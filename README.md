# Spark_WordCount
完成  单机版spark环境搭建  +  Spark平台的词频统计

1.	安装scala并配置环境变量。

![image](https://github.com/wuhuanqi/Spark_WordCount/blob/master/images/1.png)

2.	配置hadoop环境变量。

![image](https://github.com/wuhuanqi/Spark_WordCount/blob/master/images/2.png)
3.	安装配置maven环境。

![image](https://github.com/wuhuanqi/Spark_WordCount/blob/master/images/3.png)
4.	安装IntelliJIDEA。为idea添加scala和maven插件。

5.	使用IntelliJIDEA构建maven项目。（配置全局sdk，添加spark依赖）
在Pom.xml文件中配置依赖：spark、Scala、hadoop版本等

![image](https://github.com/wuhuanqi/Spark_WordCount/blob/master/images/4.png)
6.	新建scala.class编译运行

![image](https://github.com/wuhuanqi/Spark_WordCount/blob/master/images/5.png)
7.	词频统计运行结果
![image](https://github.com/wuhuanqi/Spark_WordCount/blob/master/images/6.png)
